apiVersion: operators.coreos.com/v1alpha1
kind: ClusterServiceVersion
metadata:
  annotations:
    alm-examples: |-
      [
        {
          "apiVersion": "remediation.medik8s.io/v1alpha1",
          "kind": "NodeHealthCheck",
          "metadata": {
            "name": "nodehealthcheck-sample"
          },
          "spec": {
            "minHealthy": "51%",
            "remediationTemplate": {
              "apiVersion": "self-node-remediation.medik8s.io/v1alpha1",
              "kind": "SelfNodeRemediationTemplate",
              "name": "self-node-remediation-automatic-strategy-template",
              "namespace": "openshift-operators"
            },
            "selector": {
              "matchExpressions": [
                {
                  "key": "node-role.kubernetes.io/worker",
                  "operator": "Exists"
                }
              ]
            },
            "unhealthyConditions": [
              {
                "duration": "300s",
                "status": "False",
                "type": "Ready"
              },
              {
                "duration": "300s",
                "status": "Unknown",
                "type": "Ready"
              }
            ]
          }
        }
      ]
    capabilities: Basic Install
    categories: OpenShift Optional
    console.openshift.io/plugins: '["node-remediation-console-plugin"]'
    containerImage: quay.io/medik8s/node-healthcheck-operator:v0.0.1
    createdAt: ""
    description: Detect failed Nodes and trigger remediation with e.g. Self Node Remediation.
    olm.skipRange: '>=0.0.1'
    operators.operatorframework.io/builder: operator-sdk-v1.31.0
    operators.operatorframework.io/project_layout: go.kubebuilder.io/v3
    repository: https://github.com/medik8s/node-healthcheck-operator
    support: Medik8s
  name: node-healthcheck-operator.v0.0.1
  namespace: placeholder
spec:
  apiservicedefinitions: {}
  customresourcedefinitions:
    owned:
    - description: NodeHealthCheck is the Schema for the nodehealthchecks API
      displayName: Node Health Check
      kind: NodeHealthCheck
      name: nodehealthchecks.remediation.medik8s.io
      resources:
      - kind: NodeHealthCheck
        name: nodehealthchecks
        version: v1alpha1
      specDescriptors:
      - description: "EscalatingRemediations contain a list of ordered remediation
          templates with a timeout. The remediation templates will be used one after
          another, until the unhealthy node gets healthy within the timeout of the
          currently processed remediation. The order of remediation is defined by
          the \"order\" field of each \"escalatingRemediation\". \n Mutually exclusive
          with RemediationTemplate"
        displayName: Escalating Remediations
        path: escalatingRemediations
      - description: Order defines the order for this remediation. Remediations with
          lower order will be used before remediations with higher order. Remediations
          must not have the same order.
        displayName: Order
        path: escalatingRemediations[0].order
      - description: "RemediationTemplate is a reference to a remediation template
          provided by a remediation provider. \n If a node needs remediation the controller
          will create an object from this template and then it should be picked up
          by a remediation provider."
        displayName: Remediation Template
        path: escalatingRemediations[0].remediationTemplate
      - description: "Timeout defines how long NHC will wait for the node getting
          healthy before the next remediation (if any) will be used. When the last
          remediation times out, the overall remediation is considered as failed.
          As a safeguard for preventing parallel remediations, a minimum of 60s is
          enforced. \n Expects a string of decimal numbers each with optional fraction
          and a unit suffix, eg \"300ms\", \"1.5h\" or \"2h45m\". Valid time units
          are \"ns\", \"us\" (or \"µs\"), \"ms\", \"s\", \"m\", \"h\"."
        displayName: Timeout
        path: escalatingRemediations[0].timeout
      - description: Remediation is allowed if at least "MinHealthy" nodes selected
          by "selector" are healthy. Expects either a positive integer value or a
          percentage value. Percentage values must be positive whole numbers and are
          capped at 100%. 100% is valid and will block all remediation.
        displayName: Min Healthy
        path: minHealthy
      - description: 'PauseRequests will prevent any new remediation to start, while
          in-flight remediations keep running. Each entry is free form, and ideally
          represents the requested party reason for this pausing - i.e: "imaginary-cluster-upgrade-manager-operator"'
        displayName: Pause Requests
        path: pauseRequests
      - description: "RemediationTemplate is a reference to a remediation template
          provided by an infrastructure provider. \n If a node needs remediation the
          controller will create an object from this template and then it should be
          picked up by a remediation provider. \n Mutually exclusive with EscalatingRemediations"
        displayName: Remediation Template
        path: remediationTemplate
      - description: "Label selector to match nodes whose health will be exercised.
          \n Selecting both control-plane and worker nodes in one NHC CR is highly
          discouraged and can result in undesired behaviour. \n Note: mandatory now
          for above reason, but for backwards compatibility existing CRs will continue
          to work with an empty selector, which matches all nodes."
        displayName: Selector
        path: selector
      - description: UnhealthyConditions contains a list of the conditions that determine
          whether a node is considered unhealthy.  The conditions are combined in
          a logical OR, i.e. if any of the conditions is met, the node is unhealthy.
        displayName: Unhealthy Conditions
        path: unhealthyConditions
      - description: "Duration of the condition specified when a node is considered
          unhealthy. \n Expects a string of decimal numbers each with optional fraction
          and a unit suffix, eg \"300ms\", \"1.5h\" or \"2h45m\". Valid time units
          are \"ns\", \"us\" (or \"µs\"), \"ms\", \"s\", \"m\", \"h\"."
        displayName: Duration
        path: unhealthyConditions[0].duration
      - description: The condition status in the node's status to watch for. Typically
          False, True or Unknown.
        displayName: Status
        path: unhealthyConditions[0].status
      - description: The condition type in the node's status to watch for.
        displayName: Type
        path: unhealthyConditions[0].type
      statusDescriptors:
      - description: 'Represents the observations of a NodeHealthCheck''s current
          state. Known .status.conditions.type are: "Disabled"'
        displayName: Conditions
        path: conditions
        x-descriptors:
        - urn:alm:descriptor:io.kubernetes.conditions
      - description: HealthyNodes specified the number of healthy nodes observed
        displayName: Healthy Nodes
        path: healthyNodes
      - description: InFlightRemediations records the timestamp when remediation triggered
          per node. Deprecated in favour of UnhealthyNodes.
        displayName: In Flight Remediations
        path: inFlightRemediations
      - description: LastUpdateTime is the last time the status was updated.
        displayName: Last Update Time
        path: lastUpdateTime
      - description: ObservedNodes specified the number of nodes observed by using
          the NHC spec.selector
        displayName: Observed Nodes
        path: observedNodes
      - description: Phase represents the current phase of this Config. Known phases
          are Disabled, Paused, Remediating and Enabled, based on:\n - the status
          of the Disabled condition\n - the value of PauseRequests\n - the value of
          InFlightRemediations
        displayName: Phase
        path: phase
        x-descriptors:
        - urn:alm:descriptor:io.kubernetes.phase
      - description: Reason explains the current phase in more detail.
        displayName: Reason
        path: reason
        x-descriptors:
        - urn:alm:descriptor:io.kubernetes.phase:reason
      - description: UnhealthyNodes tracks currently unhealthy nodes and their remediations.
        displayName: Unhealthy Nodes
        path: unhealthyNodes
      - description: ConditionsHealthyTimestamp is RFC 3339 date and time at which
          the unhealthy conditions didn't match anymore. The remediation CR will be
          deleted at that time, but the node will still be tracked as unhealthy until
          all remediation CRs are actually deleted, when remediators finished cleanup
          and removed their finalizers.
        displayName: Conditions Healthy Timestamp
        path: unhealthyNodes[0].conditionsHealthyTimestamp
      - description: Name is the name of the unhealthy node
        displayName: Name
        path: unhealthyNodes[0].name
      - description: Remediations tracks the remediations created for this node
        displayName: Remediations
        path: unhealthyNodes[0].remediations
      - description: Resource is the reference to the remediation CR which was created
        displayName: Resource
        path: unhealthyNodes[0].remediations[0].resource
      - description: Started is the creation time of the remediation CR
        displayName: Started
        path: unhealthyNodes[0].remediations[0].started
      - description: TimedOut is the time when the remediation timed out. Applicable
          for escalating remediations only.
        displayName: Timed Out
        path: unhealthyNodes[0].remediations[0].timedOut
      version: v1alpha1
  description: |
    ### Introduction
    Hardware is imperfect, and software contains bugs. When node level failures such as kernel hangs or dead NICs
    occur, the work required from the cluster does not decrease - workloads from affected nodes need to be
    restarted somewhere.

    However some workloads, such as RWO volumes and StatefulSets, may require at-most-one semantics.
    Failures affecting these kind of workloads risk data loss and/or corruption if nodes (and the workloads
    running on them) are assumed to be dead whenever we stop hearing from them. For this reason it is important
    to know that the node has reached a safe state before initiating recovery of the workload.

    Unfortunately it is not always practical to require admin intervention in order to confirm the node’s true status.
    In order to automate the recovery of exclusive workloads, we provide operators for failure detection
    and remediation.

    ### Failure detection: Node Health Check operator
    The “Node Health Check” (NHC) operator checks each Node’s set of
    NodeConditions (eg. NotReady) against the criteria and thresholds defined in
    NodeHealthCheck configuration. If the Node is deemed to be in a failed
    state, NHC will initiate recovery by using the SIG Cluster API's “External
    Remediation” API to instantiate the configured remediation template which
    specifies the mechanism/controller to be used.

    ### Failure handling: Self Node Remediation
    By default NHC depends on the “Self Node Remediation” (SNR) operator, which
    is installed automatically.
    SNR uses watchdog timers and heuristics to ensure nodes enter a safe state
    (no longer hosting workloads) within a known and finite period of time,
    before signaling to the system that all Pods and VolumeAttachments on the
    failed Node are no longer active and can be relocated elsewhere.
    In the case of transient errors, the watchdog’s actions will also result in
    the node rebooting and rejoining the cluster - restoring capacity.
  displayName: Node Health Check Operator
  icon:
  - base64data: base64EncodedIcon
    mediatype: image/png
  install:
    spec:
      clusterPermissions:
      - rules:
        - apiGroups:
          - apps
          resources:
          - deployments
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - config.openshift.io
          resources:
          - clusterversions
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - config.openshift.io
          resources:
          - featuregates
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - console.openshift.io
          resources:
          - consoleplugins
          verbs:
          - create
          - delete
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - coordination.k8s.io
          resources:
          - leases
          verbs:
          - create
          - delete
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - ""
          resources:
          - namespaces
          verbs:
          - create
          - get
        - apiGroups:
          - ""
          resources:
          - nodes
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - machine.openshift.io
          resources:
          - machinehealthchecks
          verbs:
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - machine.openshift.io
          resources:
          - machinehealthchecks/status
          verbs:
          - get
          - patch
          - update
        - apiGroups:
          - machine.openshift.io
          resources:
          - machines
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - policy
          resources:
          - poddisruptionbudgets
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - rbac.authorization.k8s.io
          resources:
          - clusterrolebindings
          verbs:
          - '*'
        - apiGroups:
          - rbac.authorization.k8s.io
          resources:
          - clusterroles
          verbs:
          - '*'
        - apiGroups:
          - remediation.medik8s.io
          resources:
          - nodehealthchecks
          verbs:
          - create
          - delete
          - get
          - list
          - patch
          - update
          - watch
        - apiGroups:
          - remediation.medik8s.io
          resources:
          - nodehealthchecks/finalizers
          verbs:
          - update
        - apiGroups:
          - remediation.medik8s.io
          resources:
          - nodehealthchecks/status
          verbs:
          - get
          - patch
          - update
        - apiGroups:
          - authentication.k8s.io
          resources:
          - tokenreviews
          verbs:
          - create
        - apiGroups:
          - authorization.k8s.io
          resources:
          - subjectaccessreviews
          verbs:
          - create
        serviceAccountName: node-healthcheck-controller-manager
      deployments:
      - label:
          app.kubernetes.io/component: controller-manager
          app.kubernetes.io/name: node-healthcheck-operator
        name: node-healthcheck-controller-manager
        spec:
          replicas: 2
          selector:
            matchLabels:
              app.kubernetes.io/component: controller-manager
              app.kubernetes.io/name: node-healthcheck-operator
          strategy: {}
          template:
            metadata:
              annotations:
                kubectl.kubernetes.io/default-container: manager
              labels:
                app.kubernetes.io/component: controller-manager
                app.kubernetes.io/name: node-healthcheck-operator
            spec:
              affinity:
                nodeAffinity:
                  preferredDuringSchedulingIgnoredDuringExecution:
                  - preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/infra
                        operator: Exists
                    weight: 3
                  - preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/master
                        operator: Exists
                    weight: 1
                  - preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
                    weight: 1
              containers:
              - args:
                - --secure-listen-address=0.0.0.0:8443
                - --http2-disable
                - --upstream=http://127.0.0.1:8080/
                - --logtostderr=true
                - --v=10
                image: quay.io/brancz/kube-rbac-proxy:v0.15.0
                name: kube-rbac-proxy
                ports:
                - containerPort: 8443
                  name: https
                resources:
                  limits:
                    cpu: 500m
                    memory: 128Mi
                  requests:
                    cpu: 5m
                    memory: 64Mi
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
              - args:
                - --health-probe-bind-address=:8081
                - --metrics-bind-address=127.0.0.1:8080
                - --leader-elect
                command:
                - /manager
                env:
                - name: DEPLOYMENT_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
                image: quay.io/medik8s/node-healthcheck-operator:latest
                livenessProbe:
                  httpGet:
                    path: /healthz
                    port: 8081
                  initialDelaySeconds: 15
                  periodSeconds: 20
                name: manager
                readinessProbe:
                  httpGet:
                    path: /readyz
                    port: 8081
                  initialDelaySeconds: 5
                  periodSeconds: 10
                resources:
                  requests:
                    cpu: 100m
                    memory: 20Mi
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
              priorityClassName: system-cluster-critical
              securityContext:
                runAsNonRoot: true
              serviceAccountName: node-healthcheck-controller-manager
              terminationGracePeriodSeconds: 10
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/master
                operator: Exists
              - effect: NoSchedule
                key: node-role.kubernetes.io/control-plane
                operator: Exists
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
              - effect: NoExecute
                key: node-role.kubernetes.io/infra
                operator: Exists
      - label:
          app.kubernetes.io/component: node-remediation-console-plugin
          app.kubernetes.io/name: node-healthcheck-operator
        name: node-healthcheck-node-remediation-console-plugin
        spec:
          replicas: 1
          selector:
            matchLabels:
              app.kubernetes.io/component: node-remediation-console-plugin
              app.kubernetes.io/name: node-healthcheck-operator
          strategy: {}
          template:
            metadata:
              labels:
                app.kubernetes.io/component: node-remediation-console-plugin
                app.kubernetes.io/name: node-healthcheck-operator
            spec:
              affinity:
                nodeAffinity:
                  preferredDuringSchedulingIgnoredDuringExecution:
                  - preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/infra
                        operator: Exists
                    weight: 3
                  - preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/master
                        operator: Exists
                    weight: 1
                  - preference:
                      matchExpressions:
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
                    weight: 1
              containers:
              - image: quay.io/medik8s/node-remediation-console:latest
                name: node-remediation-console-plugin
                ports:
                - containerPort: 9443
                  name: nrc-server
                  protocol: TCP
                resources:
                  requests:
                    cpu: 10m
                    memory: 50Mi
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
                volumeMounts:
                - mountPath: /var/serving-cert
                  name: nrc-plugin-cert
                  readOnly: true
              securityContext:
                runAsNonRoot: true
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/master
                operator: Exists
              - effect: NoSchedule
                key: node-role.kubernetes.io/control-plane
                operator: Exists
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
              - effect: NoExecute
                key: node-role.kubernetes.io/infra
                operator: Exists
              volumes:
              - name: nrc-plugin-cert
                secret:
                  defaultMode: 420
                  secretName: nrc-plugin-cert
      permissions:
      - rules:
        - apiGroups:
          - ""
          resources:
          - configmaps
          verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - coordination.k8s.io
          resources:
          - leases
          verbs:
          - get
          - list
          - watch
          - create
          - update
          - patch
          - delete
        - apiGroups:
          - ""
          resources:
          - events
          verbs:
          - create
          - patch
        serviceAccountName: node-healthcheck-controller-manager
    strategy: deployment
  installModes:
  - supported: false
    type: OwnNamespace
  - supported: false
    type: SingleNamespace
  - supported: false
    type: MultiNamespace
  - supported: true
    type: AllNamespaces
  keywords:
  - NHC
  - Self Node Remediation
  - SNR
  - Remediation
  - Fencing
  - medik8s
  - k8s
  links:
  - name: Node Healthcheck Operator
    url: https://medik8s.io
  - name: Source Code
    url: https://github.com/medik8s/node-healthcheck-operator
  maintainers:
  - email: medik8s@googlegroups.com
    name: Medik8s Team
  maturity: alpha
  minKubeVersion: 1.20.0
  provider:
    name: Medik8s
    url: https://github.com/medik8s
  version: 0.0.1
  webhookdefinitions:
  - admissionReviewVersions:
    - v1
    containerPort: 443
    deploymentName: node-healthcheck-controller-manager
    failurePolicy: Fail
    generateName: vnodehealthcheck.kb.io
    rules:
    - apiGroups:
      - remediation.medik8s.io
      apiVersions:
      - v1alpha1
      operations:
      - CREATE
      - UPDATE
      - DELETE
      resources:
      - nodehealthchecks
    sideEffects: None
    targetPort: 9443
    type: ValidatingAdmissionWebhook
    webhookPath: /validate-remediation-medik8s-io-v1alpha1-nodehealthcheck
