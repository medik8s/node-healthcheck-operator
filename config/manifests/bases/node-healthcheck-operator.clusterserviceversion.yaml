apiVersion: operators.coreos.com/v1alpha1
kind: ClusterServiceVersion
metadata:
  annotations:
    alm-examples: '[]'
    capabilities: Basic Install
    categories: OpenShift Optional
    console.openshift.io/plugins: '["node-remediation-console-plugin"]'
    containerImage: ""
    createdAt: ""
    description: Detect failed Nodes and trigger remediation with e.g. Self Node Remediation.
    olm.skipRange: '>=0.2.0 <0.3.0'
    repository: https://github.com/medik8s/node-healthcheck-operator
    support: Medik8s
  name: node-healthcheck-operator.v0.0.0
  namespace: placeholder
spec:
  apiservicedefinitions: {}
  customresourcedefinitions:
    owned:
    - description: NodeHealthCheck is the Schema for the nodehealthchecks API
      displayName: Node Health Check
      kind: NodeHealthCheck
      name: nodehealthchecks.remediation.medik8s.io
      resources:
      - kind: NodeHealthCheck
        name: nodehealthchecks
        version: v1alpha1
      specDescriptors:
      - description: Remediation is allowed if at least "MinHealthy" nodes selected
          by "selector" are healthy. Expects either a positive integer value or a
          percentage value. Percentage values must be positive whole numbers and are
          capped at 100%. 100% is valid and will block all remediation.
        displayName: Min Healthy
        path: minHealthy
      - description: 'PauseRequests will prevent any new remdiation to start, while
          in-flight remediations keep running. Each entry is free form, and ideally
          represents the requested party reason for this pausing - i.e: "imaginary-cluster-upgrade-manager-operator"'
        displayName: Pause Requests
        path: pauseRequests
      - description: "RemediationTemplate is a reference to a remediation template
          provided by an infrastructure provider. \n If a node needs remediation the
          controller will create an object from this template and then it should be
          picked up by a remediation provider."
        displayName: Remediation Template
        path: remediationTemplate
      - description: 'Label selector to match nodes whose health will be exercised.
          Note: An empty selector will match all nodes.'
        displayName: Selector
        path: selector
      - description: UnhealthyConditions contains a list of the conditions that determine
          whether a node is considered unhealthy.  The conditions are combined in
          a logical OR, i.e. if any of the conditions is met, the node is unhealthy.
        displayName: Unhealthy Conditions
        path: unhealthyConditions
      statusDescriptors:
      - description: 'Represents the observations of a NodeHealthCheck''s current
          state. Known .status.conditions.type are: "Disabled"'
        displayName: conditions
        path: conditions
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:conditions
      - description: HealthyNodes specified the number of healthy nodes observed
        displayName: healthynodes
        path: healthyNodes
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:healthyNodes
      - description: InFlightRemediations records the timestamp when remediation triggered
          per node
        displayName: inFlightRemediations
        path: inFlightRemediations
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:inFlightRemediations
      - description: ObservedNodes specified the number of nodes observed by using
          the NHC spec.selecor
        displayName: observedNodes
        path: observedNodes
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:observedNodes
      - description: Phase represents the current phase of this Config. Known phases
          are Disabled, Paused, Remediating and Enabled, based on:\n - the status
          of the Disabled condition\n - the value of PauseRequests\n - the value of
          InFlightRemediations
        displayName: phase
        path: phase
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:text
      - description: Reason explains the current phase in more detail.
        displayName: reason
        path: reason
        x-descriptors:
        - urn:alm:descriptor:com.tectonic.ui:text
      version: v1alpha1
  description: |
    ### Introduction
    Hardware is imperfect, and software contains bugs. When node level failures such as kernel hangs or dead NICs
    occur, the work required from the cluster does not decrease - workloads from affected nodes need to be
    restarted somewhere.

    However some workloads, such as RWO volumes and StatefulSets, may require at-most-one semantics.
    Failures affecting these kind of workloads risk data loss and/or corruption if nodes (and the workloads
    running on them) are assumed to be dead whenever we stop hearing from them. For this reason it is important
    to know that the node has reached a safe state before initiating recovery of the workload.

    Unfortunately it is not always practical to require admin intervention in order to confirm the node’s true status.
    In order to automate the recovery of exclusive workloads, we provide operators for failure detection
    and remediation.

    ### Failure detection: Node Health Check operator
    The “Node Health Check” (NHC) operator checks each Node’s set of
    NodeConditions (eg. NotReady) against the criteria and thresholds defined in
    NodeHealthCheck configuration. If the Node is deemed to be in a failed
    state, NHC will initiate recovery by using the SIG Cluster API's “External
    Remediation” API to instantiate the configured remediation template which
    specifies the mechanism/controller to be used.

    ### Failure handling: Self Node Remediation
    By default NHC depends on the “Self Node Remediation” (SNR) operator, which
    is installed automatically.
    SNR uses watchdog timers and heuristics to ensure nodes enter a safe state
    (no longer hosting workloads) within a known and finite period of time,
    before signaling to the system that all Pods and VolumeAttachments on the
    failed Node are no longer active and can be relocated elsewhere.
    In the case of transient errors, the watchdog’s actions will also result in
    the node rebooting and rejoining the cluster - restoring capacity.
  displayName: Node Health Check Operator
  icon:
  - base64data: base64EncodedIcon
    mediatype: image/png
  install:
    spec:
      deployments: null
    strategy: ""
  installModes:
  - supported: false
    type: OwnNamespace
  - supported: false
    type: SingleNamespace
  - supported: false
    type: MultiNamespace
  - supported: true
    type: AllNamespaces
  keywords:
  - NHC
  - Self Node Remediation
  - SNR
  - Remediation
  - Fencing
  - medik8s
  - k8s
  links:
  - name: Node Healthcheck Operator
    url: https://medik8s.io
  - name: Source Code
    url: https://github.com/medik8s/node-healthcheck-operator
  maintainers:
  - email: medik8s@googlegroups.com
    name: medik8s team
  maturity: alpha
  minKubeVersion: 1.20.0
  provider:
    name: medik8s
    url: https://github.com/medik8s
  version: 0.0.0
